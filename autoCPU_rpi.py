#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‘è“æ´¾ä¸“ç”¨CPUåŸºå‡†æµ‹è¯•è„šæœ¬
åˆ©ç”¨æ ‘è“æ´¾5çš„åŸç”Ÿç¡¬ä»¶ç›‘æ§æ¥å£è¿›è¡Œç²¾ç¡®åŠŸè€—æµ‹é‡
"""

import os
import time
import threading
import subprocess
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import psutil
from tflite_runtime.interpreter import Interpreter

class RaspberryPiPowerMonitor:
    """
    æ ‘è“æ´¾ä¸“ç”¨åŠŸè€—ç›‘æ§å™¨ï¼Œä½¿ç”¨åŸç”Ÿç¡¬ä»¶æ¥å£
    """
    def __init__(self):
        self.monitoring = False
        self.power_readings = []
        self.start_time = None
        
        # æ ‘è“æ´¾ç¡¬ä»¶ç›‘æ§è·¯å¾„
        self.temp_path = "/sys/class/hwmon/hwmon0/temp1_input"
        self.volt_paths = [
            "/sys/class/hwmon/hwmon1/in1_input",  # Core voltage
            "/sys/class/hwmon/hwmon1/in2_input",  # SDRAM voltage  
            "/sys/class/hwmon/hwmon1/in3_input",  # I/O voltage
            "/sys/class/hwmon/hwmon1/in4_input"   # Other voltage
        ]
        
    def read_vcgencmd_voltage(self):
        """ä½¿ç”¨vcgencmdè¯»å–CPUæ ¸å¿ƒç”µå‹"""
        try:
            result = subprocess.run(['vcgencmd', 'measure_volts'], 
                                  capture_output=True, text=True, timeout=1)
            if result.returncode == 0:
                # è§£æè¾“å‡º "volt=0.8860V"
                volt_str = result.stdout.strip().split('=')[1].replace('V', '')
                return float(volt_str)
        except:
            pass
        return None
        
    def read_hardware_temp(self):
        """è¯»å–ç¡¬ä»¶æ¸©åº¦ä¼ æ„Ÿå™¨"""
        try:
            with open(self.temp_path, 'r') as f:
                # æ¸©åº¦å€¼ä»¥æ¯«æ‘„æ°åº¦ä¸ºå•ä½
                temp_millicelsius = int(f.read().strip())
                return temp_millicelsius / 1000.0
        except:
            return None
            
    def read_hardware_voltages(self):
        """è¯»å–ç¡¬ä»¶ç”µå‹ä¼ æ„Ÿå™¨"""
        voltages = {}
        labels = ['core', 'sdram', 'io', 'other']
        
        for i, path in enumerate(self.volt_paths):
            try:
                with open(path, 'r') as f:
                    # ç”µå‹å€¼ä»¥æ¯«ä¼ä¸ºå•ä½
                    voltage_mv = int(f.read().strip())
                    voltages[labels[i]] = voltage_mv / 1000.0
            except:
                voltages[labels[i]] = None
                
        return voltages
        
    def get_cpu_frequency(self):
        """è·å–å½“å‰CPUé¢‘ç‡"""
        try:
            cpu_freq = psutil.cpu_freq()
            if cpu_freq:
                return cpu_freq.current
        except:
            pass
        return None
        
    def get_bound_core_usage(self):
        """è·å–å½“å‰ç»‘å®šCPUæ ¸å¿ƒçš„ä½¿ç”¨ç‡"""
        try:
            # è·å–å½“å‰è¿›ç¨‹ç»‘å®šçš„CPUæ ¸å¿ƒ
            bound_cores = os.sched_getaffinity(0)
            if bound_cores:
                # è·å–å„ä¸ªæ ¸å¿ƒçš„ä½¿ç”¨ç‡
                per_cpu_usage = psutil.cpu_percent(percpu=True, interval=0.01)
                if per_cpu_usage and len(per_cpu_usage) > max(bound_cores):
                    # è¿”å›ç»‘å®šæ ¸å¿ƒçš„å¹³å‡ä½¿ç”¨ç‡
                    bound_usage = [per_cpu_usage[core] for core in bound_cores if core < len(per_cpu_usage)]
                    return np.mean(bound_usage) if bound_usage else 0.0
        except:
            pass
        return 0.0
        
    def calculate_rpi_power(self):
        """
        è®¡ç®—æ ‘è“æ´¾åŠŸè€—ï¼ˆåŸºäºå®é™…ç¡¬ä»¶æ•°æ®ï¼‰
        """
        try:
            # 1. è·å–ç¡¬ä»¶æ•°æ®
            temp = self.read_hardware_temp()
            voltages = self.read_hardware_voltages()
            core_voltage = self.read_vcgencmd_voltage()
            cpu_freq = self.get_cpu_frequency()
            cpu_usage = psutil.cpu_percent(interval=0.01)
            
            # è·å–ç»‘å®šæ ¸å¿ƒçš„ä½¿ç”¨ç‡
            bound_core_usage = self.get_bound_core_usage()
            
            # 2. æ ‘è“æ´¾5åŠŸè€—æ¨¡å‹
            # åŸºç¡€åŠŸè€—ï¼šä¸»è¦æ¥è‡ªSoCå’Œå†…å­˜
            base_power = 1.5  # æ ‘è“æ´¾5ç©ºé—²åŠŸè€—çº¦1.5W
            
            # CPUåŠ¨æ€åŠŸè€—è®¡ç®—
            cpu_power = 0
            bound_core_power = 0
            
            if core_voltage and cpu_freq:
                # åŠŸè€— â‰ˆ C Ã— VÂ² Ã— f ï¼ˆCä¸ºå®¹æ€§è´Ÿè½½å¸¸æ•°ï¼‰
                # æ ‘è“æ´¾5 CPUæœ€å¤§åŠŸè€—çº¦4-6W
                freq_factor = cpu_freq / 2400.0  # æ ‡å‡†åŒ–åˆ°2.4GHz
                voltage_factor = (core_voltage / 0.9) ** 2  # æ ‡å‡†åŒ–åˆ°0.9V
                usage_factor = cpu_usage / 100.0
                
                cpu_power = 4.0 * freq_factor * voltage_factor * usage_factor
                
                # è®¡ç®—ç»‘å®šæ ¸å¿ƒçš„åŠŸè€—ï¼ˆå•æ ¸å¿ƒçš„ç†è®ºæœ€å¤§åŠŸè€—çº¦1Wï¼‰
                bound_core_usage_factor = bound_core_usage / 100.0
                bound_core_power = 1.0 * freq_factor * voltage_factor * bound_core_usage_factor
            else:
                # ç®€åŒ–ä¼°ç®—
                cpu_power = 3.0 * (cpu_usage / 100.0)
                bound_core_power = 0.75 * (bound_core_usage / 100.0)
                
            # æ¸©åº¦ä¿®æ­£
            temp_factor = 1.0
            if temp:
                # æ¸©åº¦é«˜æ—¶æ•ˆç‡ä¸‹é™ï¼ŒåŠŸè€—å¢åŠ 
                if temp > 60:
                    temp_factor = 1.0 + (temp - 60) * 0.005
                    
            # æ€»åŠŸè€—
            total_power = (base_power + cpu_power) * temp_factor
            bound_core_power *= temp_factor
            
            return total_power, {
                'temperature': temp,
                'core_voltage': core_voltage,
                'cpu_frequency': cpu_freq,
                'cpu_usage': cpu_usage,
                'bound_core_usage': bound_core_usage,
                'voltages': voltages,
                'base_power': base_power,
                'cpu_power': cpu_power,
                'bound_core_power': bound_core_power,
                'temp_factor': temp_factor
            }
            
        except Exception as e:
            print(f"Error calculating RPI power: {e}")
            return 2.0, {}
            
    def start_monitoring(self):
        """å¼€å§‹åŠŸè€—ç›‘æ§"""
        self.monitoring = True
        self.power_readings = []
        self.start_time = time.time()
        
        def monitor():
            while self.monitoring:
                power, details = self.calculate_rpi_power()
                timestamp = time.time() - self.start_time
                self.power_readings.append({
                    'timestamp': timestamp,
                    'power': power,
                    **details
                })
                time.sleep(0.005)  # 5msé‡‡æ ·ç‡ï¼Œæ›´ç²¾ç¡®
                
        self.monitor_thread = threading.Thread(target=monitor)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
    def stop_monitoring(self):
        """åœæ­¢åŠŸè€—ç›‘æ§å¹¶è¿”å›ç»Ÿè®¡æ•°æ®"""
        self.monitoring = False
        if hasattr(self, 'monitor_thread'):
            self.monitor_thread.join(timeout=1.0)
            
        if self.power_readings:
            powers = [reading['power'] for reading in self.power_readings]
            bound_core_powers = [reading.get('bound_core_power', 0) for reading in self.power_readings]
            
            return {
                'avg_power': np.mean(powers),
                'min_power': np.min(powers),
                'max_power': np.max(powers),
                'std_power': np.std(powers),
                'avg_bound_core_power': np.mean(bound_core_powers),
                'min_bound_core_power': np.min(bound_core_powers),
                'max_bound_core_power': np.max(bound_core_powers),
                'std_bound_core_power': np.std(bound_core_powers),
                'readings': self.power_readings,
                'sample_count': len(self.power_readings)
            }
        return {
            'avg_power': 2.0, 
            'avg_bound_core_power': 0.0,
            'readings': [], 
            'sample_count': 0
        }

def set_rpi_normal_mode():
    """
    è®¾ç½®æ ‘è“æ´¾ä¸ºæ™®é€šæ¨¡å¼ï¼Œé¿å…è¶…é¢‘ï¼Œä½¿ç”¨CPUæ ¸å¿ƒ1-3ï¼ˆé¿å…æ ¸å¿ƒ0ï¼‰
    """
    try:
        # è®¾ç½®CPUè°ƒåº¦å™¨ä¸ºondemandï¼ˆæ™®é€šæ¨¡å¼ï¼Œéè¶…é¢‘ï¼‰
        subprocess.run(['sudo', 'cpufreq-set', '-g', 'ondemand'], 
                      capture_output=True)
        print("Set CPU governor to ondemand mode (normal frequency scaling)")
        
        # è®¾ç½®CPUäº²å’Œæ€§åˆ°æ ¸å¿ƒ1ï¼ˆé¿å…ä½¿ç”¨æ ¸å¿ƒ0ï¼‰
        available_cores = list(range(1, os.cpu_count()))  # ä½¿ç”¨æ ¸å¿ƒ1å¼€å§‹çš„å¯ç”¨æ ¸å¿ƒ
        if available_cores:
            os.sched_setaffinity(0, {available_cores[0]})
            print(f"Process bound to CPU core {available_cores[0]} (avoiding core 0)")
        else:
            print("Warning: Only one CPU core available, using default scheduling")
        
        return True
    except Exception as e:
        print(f"Could not set normal mode: {e}")
        return False

def test_model_rpi(model_path, num_runs=1000):
    """
    æ ‘è“æ´¾ä¼˜åŒ–çš„æ¨¡å‹æµ‹è¯•å‡½æ•°
    """
    print(f"Testing {os.path.basename(model_path)} on Raspberry Pi...")
    
    # è®¾ç½®æ™®é€šæ¨¡å¼ï¼ˆéè¶…é¢‘ï¼‰
    set_rpi_normal_mode()
    
    # åŠ è½½æ¨¡å‹
    interpreter = Interpreter(model_path=model_path)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    input_shape = input_details[0]['shape']
    if input_details[0]['dtype'] == np.uint8:
        dummy_input = np.random.randint(0, 256, input_shape, dtype=np.uint8)
    else:
        dummy_input = np.random.rand(*input_shape).astype(np.float32)
    
    # åˆ›å»ºåŠŸè€—ç›‘æ§å™¨
    power_monitor = RaspberryPiPowerMonitor()
    
    # é¢„çƒ­
    print("Warming up (50 runs)...")
    for _ in range(50):
        interpreter.set_tensor(input_details[0]['index'], dummy_input)
        interpreter.invoke()
    
    # ç­‰å¾…ç³»ç»Ÿç¨³å®š
    time.sleep(1.0)
    
    # æµ‹é‡åŸºçº¿åŠŸè€—
    print("Measuring baseline power (3 seconds)...")
    power_monitor.start_monitoring()
    time.sleep(3.0)
    baseline_stats = power_monitor.stop_monitoring()
    baseline_power = baseline_stats['avg_power']
    baseline_bound_core_power = baseline_stats['avg_bound_core_power']
    
    print(f"Baseline power: {baseline_power:.3f} W (from {baseline_stats['sample_count']} samples)")
    print(f"Baseline bound core power: {baseline_bound_core_power:.3f} W")
    
    # æ­£å¼æµ‹è¯•
    inference_times = []
    test_power_readings = []
    bound_core_power_readings = []
    
    print(f"Running {num_runs} inferences...")
    
    # åˆ†æ‰¹æµ‹è¯•ï¼Œæ¯æ‰¹50æ¬¡æ¨ç†
    batch_size = 50
    batches = num_runs // batch_size
    
    for batch in range(batches):
        if batch % 5 == 0:
            print(f"Batch {batch + 1}/{batches}")
        
        # å¼€å§‹åŠŸè€—ç›‘æ§
        power_monitor.start_monitoring()
        
        batch_times = []
        for i in range(batch_size):
            start_time = time.perf_counter()
            interpreter.set_tensor(input_details[0]['index'], dummy_input)
            interpreter.invoke()
            end_time = time.perf_counter()
            
            batch_times.append((end_time - start_time) * 1000)
        
        # åœæ­¢åŠŸè€—ç›‘æ§
        power_stats = power_monitor.stop_monitoring()
        
        inference_times.extend(batch_times)
        test_power_readings.append(power_stats['avg_power'])
        bound_core_power_readings.append(power_stats['avg_bound_core_power'])
        
        # çŸ­æš‚ä¼‘æ¯
        time.sleep(0.05)
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    avg_inference_time = np.mean(inference_times)
    std_inference_time = np.std(inference_times)
    avg_test_power = np.mean(test_power_readings)
    avg_bound_core_power = np.mean(bound_core_power_readings)
    
    # è®¡ç®—æ¨ç†ç›¸å…³åŠŸè€—
    inference_power = max(0, avg_test_power - baseline_power)
    inference_bound_core_power = max(0, avg_bound_core_power - baseline_bound_core_power)
    
    # è®¡ç®—èƒ½æ•ˆ
    energy_per_inference = (avg_test_power * avg_inference_time) / 1000  # mJ
    
    results = {
        'avg_time_ms': avg_inference_time,
        'std_time_ms': std_inference_time,
        'avg_power_w': avg_test_power,  # ç³»ç»Ÿæ€»åŠŸè€—
        'avg_bound_core_power_w': avg_bound_core_power,  # ç»‘å®šæ ¸å¿ƒåŠŸè€—
        'baseline_power_w': baseline_power,
        'baseline_bound_core_power_w': baseline_bound_core_power,
        'inference_power_w': inference_power,
        'inference_bound_core_power_w': inference_bound_core_power,
        'energy_per_inference_mj': energy_per_inference,
        'min_time_ms': np.min(inference_times),
        'max_time_ms': np.max(inference_times),
        'total_runs': len(inference_times)
    }
    
    print(f"Results:")
    print(f"  Average inference time: {avg_inference_time:.3f} Â± {std_inference_time:.3f} ms")
    print(f"  System power: {avg_test_power:.3f} W (baseline: {baseline_power:.3f} W)")
    print(f"  Bound core power: {avg_bound_core_power:.3f} W (baseline: {baseline_bound_core_power:.3f} W)")
    print(f"  Inference power (system): {inference_power:.3f} W")
    print(f"  Inference power (bound core): {inference_bound_core_power:.3f} W")
    print(f"  Energy per inference: {energy_per_inference:.3f} mJ")
    
    return results

def visualize_rpi_results(all_results):
    """
    å¯è§†åŒ–æ ‘è“æ´¾æµ‹è¯•ç»“æœ
    """
    if not all_results:
        print("No results to visualize")
        return
    
    layer_types = [r['layer_type'] for r in all_results]
    
    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. æ¨ç†æ—¶é—´
    times = [r['avg_time_ms'] for r in all_results]
    time_stds = [r['std_time_ms'] for r in all_results]
    bars1 = ax1.bar(layer_types, times, yerr=time_stds, capsize=5, 
                   alpha=0.8, color='lightblue', edgecolor='navy')
    ax1.set_title('Raspberry Pi 5 - Inference Time', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Time (ms)')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3)
    
    for bar, time_val, std_val in zip(bars1, times, time_stds):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + std_val,
                f'{time_val:.2f}Â±{std_val:.2f}',
                ha='center', va='bottom', fontsize=9)
    
    # 2. åŠŸè€—å¯¹æ¯”ï¼ˆåŒ…å«ç»‘å®šæ ¸å¿ƒåŠŸè€—ï¼‰
    baseline_powers = [r.get('baseline_power_w', 0) for r in all_results]
    test_powers = [r['avg_power_w'] for r in all_results]  # ç³»ç»Ÿæ€»åŠŸè€—
    bound_core_powers = [r.get('avg_bound_core_power_w', 0) for r in all_results]  # ç»‘å®šæ ¸å¿ƒåŠŸè€—
    
    x = np.arange(len(layer_types))
    width = 0.25
    
    ax2.bar(x - width, baseline_powers, width, label='Baseline (System)', 
           alpha=0.8, color='lightgreen', edgecolor='darkgreen')
    ax2.bar(x, test_powers, width, label='System Power', 
           alpha=0.8, color='orange', edgecolor='darkorange')
    ax2.bar(x + width, bound_core_powers, width, label='Bound Core Power', 
           alpha=0.8, color='red', edgecolor='darkred')
    
    ax2.set_title('Raspberry Pi 5 - Power Consumption', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Power (W)')
    ax2.set_xticks(x)
    ax2.set_xticklabels(layer_types, rotation=45)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. æ¯æ¬¡æ¨ç†èƒ½è€—
    energies = [r.get('energy_per_inference_mj', 0) for r in all_results]
    bars3 = ax3.bar(layer_types, energies, alpha=0.8, color='purple', edgecolor='darkmagenta')
    ax3.set_title('Energy per Inference', fontsize=14, fontweight='bold')
    ax3.set_ylabel('Energy (mJ)')
    ax3.tick_params(axis='x', rotation=45)
    ax3.grid(True, alpha=0.3)
    
    for bar, energy in zip(bars3, energies):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{energy:.2f}',
                ha='center', va='bottom', fontsize=9)
    
    # 4. æ•ˆç‡å¯¹æ¯” (æ¨ç†æ¬¡æ•°/ç§’/ç“¦ç‰¹)
    efficiency = [1000 / (r['avg_time_ms'] * r['avg_power_w']) 
                 for r in all_results]
    bars4 = ax4.bar(layer_types, efficiency, alpha=0.8, color='gold', edgecolor='darkorange')
    ax4.set_title('Power Efficiency (inferences/s/W)', fontsize=14, fontweight='bold')
    ax4.set_ylabel('Efficiency')
    ax4.tick_params(axis='x', rotation=45)
    ax4.grid(True, alpha=0.3)
    
    for bar, eff in zip(bars4, efficiency):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{eff:.1f}',
                ha='center', va='bottom', fontsize=9)
    
    plt.suptitle('Raspberry Pi 5 CPU Benchmark Results', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    os.makedirs("./results", exist_ok=True)
    plt.savefig("./results/cpu_benchmark.png", dpi=300, bbox_inches='tight')  # ä¿®æ”¹æ–‡ä»¶åä»¥ä¾¿å¯¹æ¯”
    print("Raspberry Pi visualization saved to ./results/cpu_benchmark.png")
    plt.show()

def main():
    """
    ä¸»å‡½æ•° - è¿è¡Œæ ‘è“æ´¾CPUåŸºå‡†æµ‹è¯•
    """
    # CPUæ¨¡å‹é…ç½®
    model_configs = [
        "conv2d_cpu.tflite",
        "depthwise_conv2d_cpu.tflite",
        "separable_conv_cpu.tflite", 
        "max_pool_cpu.tflite",
        "avg_pool_cpu.tflite",
        "dense_cpu.tflite",
        "feature_pyramid_cpu.tflite",
        "detection_head_cpu.tflite"
    ]
    
    models_dir = "./cpu"
    results = []
    
    print("=" * 70)
    print("ğŸ“ Raspberry Pi 5 CPU Benchmark Test")
    print("=" * 70)
    print("Using native hardware monitoring for accurate power measurement")
    print()
    
    for model_name in model_configs:
        model_path = os.path.join(models_dir, model_name)
        if os.path.exists(model_path):
            print(f"\nğŸ“Š Testing: {model_name}")
            print("-" * 50)
            
            result = test_model_rpi(model_path, num_runs=1000)
            result.update({
                "model": model_name,
                "layer_type": model_name.replace("_cpu.tflite", ""),
                "platform": "CPU"  # ä¿®æ”¹ä¸ºä¸compare_results.pyæœŸæœ›çš„æ ¼å¼ä¸€è‡´
            })
            results.append(result)
            
            print(f"âœ… Completed: {model_name}")
            print("-" * 50)
        else:
            print(f"âŒ Model not found: {model_path}")
    
    if results:
        # ä¿å­˜è¯¦ç»†ç»“æœ
        df = pd.DataFrame(results)
        os.makedirs("./results", exist_ok=True)
        
        csv_path = "./results/cpu_benchmark_results.csv"  # ä¿®æ”¹ä¸ºä¸compare_results.pyæœŸæœ›çš„æ–‡ä»¶åä¸€è‡´
        df.to_csv(csv_path, index=False)
        print(f"\nğŸ’¾ Results saved to: {csv_path}")
        
        # æ˜¾ç¤ºæ±‡æ€»
        print("\n" + "=" * 70)
        print("ğŸ“ˆ RASPBERRY PI 5 CPU BENCHMARK SUMMARY")
        print("=" * 70)
        print(f"{'Layer Type':<15} | {'Time (ms)':<12} | {'Power (W)':<10} | {'Energy (mJ)':<12}")
        print("-" * 70)
        for result in results:
            print(f"{result['layer_type']:<15} | "
                  f"{result['avg_time_ms']:6.2f}Â±{result['std_time_ms']:4.2f} | "
                  f"{result['avg_power_w']:8.3f} | "  # ä½¿ç”¨æ–°å­—æ®µå
                  f"{result.get('energy_per_inference_mj', 0):10.3f}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        visualize_rpi_results(results)
        
        print(f"\nğŸ‰ Raspberry Pi 5 CPU benchmarking completed!")
        print(f"ğŸ“ All results saved to: ./results/")
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        temp = subprocess.run(['vcgencmd', 'measure_temp'], 
                            capture_output=True, text=True).stdout.strip()
        volt = subprocess.run(['vcgencmd', 'measure_volts'], 
                            capture_output=True, text=True).stdout.strip()
        print(f"\nğŸŒ¡ï¸  Final system state: {temp}, {volt}")
        
    else:
        print("âŒ No models found to test. Please check the ./cpu directory.")

if __name__ == "__main__":
    main()
