#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EdgeTPUåŸºå‡†æµ‹è¯•è„šæœ¬ - ç®€åŒ–ç‰ˆæœ¬ï¼ˆæ— åŠŸè€—æµ‹é‡ï¼‰
"""

import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tflite_runtime.interpreter import Interpreter
try:
    from pycoral.utils.edgetpu import make_interpreter
    from pycoral.utils import edgetpu
except ImportError:
    print("PyCoral not installed. Please install: pip install pycoral")
    exit(1)

def build_tpu_interpreter(model_path):
    """æ„å»ºTPUè§£é‡Šå™¨ï¼Œä¼˜å…ˆé€‰æ‹©USB 3.0è®¾å¤‡"""
    from pycoral.utils import edgetpu
    
    # è·å–æ‰€æœ‰å¯ç”¨çš„EdgeTPUè®¾å¤‡
    devices = edgetpu.list_edge_tpus()
    
    if not devices:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•EdgeTPUè®¾å¤‡")
        return None
    
    print(f"å‘ç° {len(devices)} ä¸ªEdgeTPUè®¾å¤‡:")
    
    # å¯»æ‰¾USB 3.0è®¾å¤‡
    usb3_device_index = None
    for i, device in enumerate(devices):
        path = device['path']
        try:
            with open(f'{path}/speed', 'r') as f:
                speed = f.read().strip()
            
            usb_type = "USB 3.0 SuperSpeed" if speed == '5000' else "USB 2.0 High Speed"
            print(f"  è®¾å¤‡ {i}: {path} ({usb_type}, {speed} Mbps)")
            
            # ä¼˜å…ˆé€‰æ‹©USB 3.0è®¾å¤‡
            if speed == '5000' and usb3_device_index is None:
                usb3_device_index = i
                
        except Exception as e:
            print(f"  è®¾å¤‡ {i}: {path} (æ— æ³•è¯»å–é€Ÿåº¦ä¿¡æ¯)")
    
    # é€‰æ‹©è®¾å¤‡ç­–ç•¥
    if usb3_device_index is not None:
        print(f"âœ… é€‰æ‹©USB 3.0è®¾å¤‡ (ç´¢å¼•: {usb3_device_index}) è·å¾—æœ€ä½³æ€§èƒ½")
        try:
            # é€šè¿‡è®¾å¤‡ç´¢å¼•æŒ‡å®šUSB 3.0è®¾å¤‡
            device_spec = f":{usb3_device_index}"
            return make_interpreter(model_path, device=device_spec)
        except Exception as e:
            print(f"âš ï¸  USB 3.0è®¾å¤‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡: {e}")
            return make_interpreter(model_path)
    else:
        print("âš ï¸  æœªæ‰¾åˆ°USB 3.0è®¾å¤‡ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡ (æ€§èƒ½å¯èƒ½å—é™)")
        return make_interpreter(model_path)

def prepare_input_data(input_details):
    """
    æ ¹æ®æ¨¡å‹è¾“å…¥è¦æ±‚å‡†å¤‡æ­£ç¡®çš„è¾“å…¥æ•°æ®
    """
    input_shape = input_details[0]['shape']
    input_dtype = input_details[0]['dtype']
    
    print(f"Model input shape: {input_shape}")
    print(f"Model input dtype: {input_dtype}")
    
    # æ ¹æ®æ•°æ®ç±»å‹å‡†å¤‡è¾“å…¥
    if input_dtype == np.uint8:
        dummy_input = np.random.randint(0, 256, input_shape, dtype=np.uint8)
    elif input_dtype == np.int8:
        dummy_input = np.random.randint(-128, 128, input_shape, dtype=np.int8)
    elif input_dtype == np.float32:
        dummy_input = np.random.rand(*input_shape).astype(np.float32)
    elif input_dtype == np.float16:
        dummy_input = np.random.rand(*input_shape).astype(np.float16)
    else:
        print(f"Warning: Unsupported input dtype {input_dtype}, using float32")
        dummy_input = np.random.rand(*input_shape).astype(np.float32)
    
    print(f"Generated input shape: {dummy_input.shape}, dtype: {dummy_input.dtype}")
    return dummy_input

def prepare_tpu_interpreter(model_path, warmup=10):
    """å‡†å¤‡TPUè§£é‡Šå™¨å¹¶è¿›è¡Œé¢„çƒ­"""
    try:
        interpreter = build_tpu_interpreter(model_path)
        if interpreter is None:
            return None, None, None, None
        interpreter.allocate_tensors()
    except Exception as e:
        print(f"Error loading TPU model {model_path}: {e}")
        return None, None, None, None
    
    # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    inp_idx = input_details[0]['index']
    out_idx = output_details[0]['index']
    
    print(f"Model has {len(input_details)} inputs and {len(output_details)} outputs")
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    dummy_input = prepare_input_data(input_details)
    
    # é¢„çƒ­ - ç¡®ä¿TPUå®Œå…¨é¢„çƒ­
    print(f"Warming up with {warmup} runs...")
    warmup_times = []
    try:
        for i in range(warmup):
            start_time = time.perf_counter()
            interpreter.set_tensor(inp_idx, dummy_input)
            interpreter.invoke()
            _ = interpreter.get_tensor(out_idx)
            end_time = time.perf_counter()
            warmup_time = (end_time - start_time) * 1000
            warmup_times.append(warmup_time)
            
            if i == 0:
                output_shape = interpreter.get_tensor(out_idx).shape
                print(f"  First warmup run: {warmup_time:.1f} ms (cold start)")
                print(f"  Output shape: {output_shape}")
            elif i == warmup - 1:
                print(f"  Last warmup run: {warmup_time:.1f} ms (warmed up)")
    except Exception as e:
        print(f"Error during warmup: {e}")
        return None, None, None, None
    
    # éªŒè¯é¢„çƒ­æ•ˆæœ
    avg_warmup = np.mean(warmup_times[1:])  # æ’é™¤ç¬¬ä¸€æ¬¡
    print(f"  Average warmup time (excluding first): {avg_warmup:.1f} ms")
    
    return interpreter, inp_idx, out_idx, dummy_input

def run_tpu_inference_once(interpreter, inp_idx, out_idx, dummy_input):
    """æ‰§è¡Œä¸€æ¬¡TPUæ¨ç†å¹¶è¿”å›å„é˜¶æ®µæ—¶é—´"""
    # æµ‹é‡å„ä¸ªé˜¶æ®µçš„æ—¶é—´
    t_a = time.perf_counter_ns()
    interpreter.set_tensor(inp_idx, dummy_input)
    t_b = time.perf_counter_ns()
    
    interpreter.invoke()
    t_c = time.perf_counter_ns()
    
    _ = interpreter.get_tensor(out_idx)
    t_d = time.perf_counter_ns()
    
    # è½¬æ¢ä¸ºæ¯«ç§’
    return ((t_b - t_a) / 1e6,  # pre: è®¾ç½®è¾“å…¥æ—¶é—´
            (t_c - t_b) / 1e6,  # infer: æ¨ç†æ—¶é—´
            (t_d - t_c) / 1e6,  # post: è·å–è¾“å‡ºæ—¶é—´
            (t_d - t_a) / 1e6)  # total: æ€»æ—¶é—´

def test_model_tpu(model_path, num_runs=1000):
    """
    æµ‹è¯•å•ä¸ªTPUæ¨¡å‹ï¼Œè¿”å›è¯¦ç»†çš„æ¨ç†ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ— åŠŸè€—æµ‹é‡ï¼‰
    """
    print(f"Testing {os.path.basename(model_path)} with {num_runs} runs...")
    
    # å‡†å¤‡è§£é‡Šå™¨
    interpreter, inp_idx, out_idx, dummy_input = prepare_tpu_interpreter(model_path, warmup=10)
    if interpreter is None:
        return None
    
    # å­˜å‚¨å„é˜¶æ®µæ—¶é—´
    pre_times = []
    infer_times = []
    post_times = []
    total_times = []
    
    print(f"Running {num_runs} inferences...")
    
    # æ‰§è¡Œæ¨ç†æµ‹è¯•
    for i in range(num_runs):
        if i % 100 == 0:
            print(f"Progress: {i}/{num_runs}")
        
        try:
            t_pre, t_infer, t_post, t_total = run_tpu_inference_once(
                interpreter, inp_idx, out_idx, dummy_input
            )
            
            pre_times.append(t_pre)
            infer_times.append(t_infer)
            post_times.append(t_post)
            total_times.append(t_total)
        except Exception as e:
            print(f"Error during inference {i}: {e}")
            break
    
    if not total_times:
        print("No successful inferences recorded")
        return None
    
    # æ£€æµ‹å¼‚å¸¸çš„å†·å¯åŠ¨
    if total_times[0] > 10:  # å¦‚æœç¬¬ä¸€æ¬¡è¶…è¿‡10msï¼Œå¯èƒ½æ˜¯å†·å¯åŠ¨
        print(f"âš ï¸  Detected cold start: first inference = {total_times[0]:.1f} ms")
        
        # æä¾›ä¸¤ç§ç»Ÿè®¡ï¼šåŒ…å«å’Œæ’é™¤å†·å¯åŠ¨
        times_without_coldstart = total_times[1:]
        print(f"  Statistics including cold start:")
        print(f"    Average: {np.mean(total_times):.3f} ms")
        print(f"  Statistics excluding cold start:")
        print(f"    Average: {np.mean(times_without_coldstart):.3f} ms")
        
        # ä½¿ç”¨æ’é™¤å†·å¯åŠ¨çš„ç»Ÿè®¡ä½œä¸ºä¸»è¦ç»“æœ
        main_times = times_without_coldstart
    else:
        main_times = total_times
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'avg_time_ms': np.mean(main_times),
        'std_time_ms': np.std(main_times),
        'min_time_ms': np.min(main_times),
        'max_time_ms': np.max(main_times),
        'avg_pre_ms': np.mean(pre_times[1:] if len(pre_times) > 1 else pre_times),
        'avg_infer_ms': np.mean(infer_times[1:] if len(infer_times) > 1 else infer_times),
        'avg_post_ms': np.mean(post_times[1:] if len(post_times) > 1 else post_times),
        'total_runs': len(main_times),
        'cold_start_detected': total_times[0] > 10 if total_times else False,
        'cold_start_time': total_times[0] if total_times else 0
    }
    
    print(f"Results:")
    print(f"  Average total time: {stats['avg_time_ms']:.3f} Â± {stats['std_time_ms']:.3f} ms")
    print(f"  Average pre time: {stats['avg_pre_ms']:.3f} ms")
    print(f"  Average inference time: {stats['avg_infer_ms']:.3f} ms")
    print(f"  Average post time: {stats['avg_post_ms']:.3f} ms")
    print(f"  Min/Max time: {stats['min_time_ms']:.3f} / {stats['max_time_ms']:.3f} ms")
    print(f"  Successful runs: {len(main_times)}/{num_runs}")
    
    return stats

def visualize_tpu_results(all_results, output_dir):
    """
    å¯è§†åŒ–EdgeTPUæµ‹è¯•ç»“æœï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    """
    if not all_results:
        print("No results to visualize")
        return
    
    layer_types = [r['layer_type'] for r in all_results]
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # æ¨ç†æ—¶é—´
    times = [r['avg_time_ms'] for r in all_results]
    time_stds = [r['std_time_ms'] for r in all_results]
    bars = ax.bar(layer_types, times, yerr=time_stds, capsize=5, 
                  alpha=0.8, color='lightgreen', edgecolor='darkgreen')
    ax.set_title('EdgeTPU - Inference Time', fontsize=14, fontweight='bold')
    ax.set_ylabel('Time (ms)')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(True, alpha=0.3)
    
    for bar, time_val, std_val in zip(bars, times, time_stds):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + std_val,
                f'{time_val:.2f} Â± {std_val:.2f}',
                ha='center', va='bottom', fontsize=9)
    
    plt.suptitle('EdgeTPU Benchmark Results', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plt.savefig(os.path.join(output_dir, "tpu_benchmark.png"), dpi=300, bbox_inches='tight')
    print(f"EdgeTPU visualization saved to {os.path.join(output_dir, 'tpu_benchmark.png')}")
    plt.show()

def main():
    """
    ä¸»å‡½æ•°
    """
    # ä½¿ç”¨å¤–é¢tpuæ–‡ä»¶å¤¹ä¸­çš„æ¨¡å‹
    model_configs = [
        "conv2d_tpu.tflite",
        "depthwise_conv2d_tpu.tflite",
        "separable_conv_tpu.tflite", 
        "dense_tpu.tflite",
        "max_pool_tpu.tflite",
        "avg_pool_tpu.tflite",
        "feature_pyramid_tpu.tflite",
        "detection_head_tpu.tflite"
    ]
    
    models_dir = "./tpu"
    results = []
    
    print("=" * 70)
    print("âš¡ EdgeTPU Benchmark Test (Simplified)")
    print("=" * 70)
    print("Testing models from ./tpu folder (çœŸæ­£çš„å¤åˆæ“ä½œå—)")
    print()
    
    for model_name in model_configs:
        model_path = os.path.join(models_dir, model_name)
        if os.path.exists(model_path):
            print(f"\nğŸ“Š Testing: {model_name}")
            print("-" * 50)
            
            result = test_model_tpu(model_path, num_runs=1000)
            if result is not None:
                result.update({
                    "model": model_name,
                    "layer_type": model_name.replace("_tpu.tflite", ""),
                    "platform": "TPU"
                })
                results.append(result)
                
                print(f"âœ… Completed: {model_name}")
            else:
                print(f"âŒ Failed: {model_name}")
            print("-" * 50)
        else:
            print(f"âŒ Model not found: {model_path}")
    
    if results:
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç‹¬ç«‹æ–‡ä»¶å¤¹
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"./results/tpu_test_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        import pandas as pd
        df = pd.DataFrame(results)
        csv_path = os.path.join(output_dir, "tpu_benchmark_results.csv")
        df.to_csv(csv_path, index=False)
        print(f"\nğŸ’¾ Results saved to: {csv_path}")
        
        # æ˜¾ç¤ºæ±‡æ€»
        print("\n" + "=" * 70)
        print("ğŸ“ˆ EDGETPU BENCHMARK SUMMARY")
        print("=" * 70)
        print(f"{'Layer Type':<20} | {'Time (ms)':<15} | {'Success':<8}")
        print("-" * 70)
        for result in results:
            print(f"{result['layer_type']:<20} | "
                  f"{result['avg_time_ms']:6.2f} Â± {result['std_time_ms']:4.2f} | "
                  f"{result['total_runs']:4d}/1000")
        
        # ç”Ÿæˆå¯è§†åŒ–åˆ°ç‹¬ç«‹æ–‡ä»¶å¤¹
        visualize_tpu_results(results, output_dir)
        
        print(f"\nğŸ‰ EdgeTPU benchmarking completed!")
        print(f"ğŸ“ All results saved to: {output_dir}/")
        
    else:
        print("âŒ No models found to test. Please check the ./tpu directory.")

if __name__ == "__main__":
    main()